\documentclass[12pt, a4paper]{article}

% USEPACKAGE ---########################################

\usepackage{amsmath, amssymb, amsfonts}
\usepackage{float}
\usepackage[polish]{babel}
\usepackage{fullpage}
\usepackage[a4paper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{enumitem}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage[labelsep=period]{caption}
\usepackage[xindy]{imakeidx}

% #####################################################


\setlength{\parindent}{1.25cm}
\setlength{\parskip}{0.3em}
\setcounter{page}{3}
\newcommand{\sectionbreak}{\clearpage}
\bibliographystyle{unsrt}

% RENEWCOMMAND ---########################################

\renewcommand{\thefigure}{\thesection.\arabic{figure}}
\addto\captionspolish{\renewcommand{\figurename}{Rys.}}
\addto\captionspolish{\renewcommand{\contentsname}{\textbf{SPIS TREŚCI}}}
\addto\captionspolish{\renewcommand{\refname}{\textbf{WYKAZ LITERATURY}}}
\addto\captionspolish{\renewcommand{\listfigurename}{\textbf{WYKAZ RYSUNKÓW}}}
\addto\captionspolish{\renewcommand{\listtablename}{\textbf{WYKAZ TABEL}}}

% #######################################################


% \captionsetup[figure]{name=Rys., labelsep=period}
% \renewcommand{\familydefault}{\arial}
% \setstretch{1.5}
\geometry{
    a4paper,
    top=2.5cm,
    bottom=2.5cm,
    inner=3.5cm,
    outer=2.5cm
    % bindingoffset=0cm, % Margines na oprawę
}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}



\begin{document}

\section*{\textbf{STRESZCZENIE}}
\newpage


\section*{\textbf{ABSTRACT}}
\newpage


\tableofcontents
\newpage


%####################################
\section*{\textbf{WYKAZ WAŻNIEJSZYCH OZNACZEŃ I SKRÓTÓW}}\setcounter{figure}{0}


\begin{itemize}[left=0pt]
    \item[] ML - Uczenie maszynowe (ang. \textit{Machine Learning})
    \item[] API - Interfejs programistyczny aplikacji (ang. \textit{Application Programming Interface})
    \item[] MLP - Wielowarstwowy perceptron (ang. \textit{Multilayer Perceptron})
    \item[] RAM
    \item[] GPU
    \item[] CPU
    \item[] RGB
    \item[] QR
    \item[] GPS
    \item[] MRI
    \item[] CT
    \item[] BPSK - binarnie kluczowana modulacja fazy (ang. Binary Phase Shift Keying)
    \item[] DNN - 
    \item[] ANN - Sztuczna sieć neuronowa (ang. \textit{Artificial Neural Network})
    \item[] CNN - Konwolucyjna sieć neuronowa (ang. \textit{Convolutional Neural Network})
    \item[] RNN - Rekurencyjna sieć neuronowa (ang. \textit{Recurrent Neural Network})
\end{itemize}

\addcontentsline{toc}{section}{Wykaz ważniejszych oznaczeń i skrótów} % Dodanie do spisu treści
\newpage
%####################################

\section{Wstęp}
    \subsection{Cel pracy}
    Celem pracy jest opracowanie przeglądu literatury metod wykorzystujących techniki uczenia maszynowego, w szczególności technik uczenia głębokiego, do poprawy jakości dekodowania wybranych korekcyjnych kodów blokowych, w szczególności kodów Reeda-Solomona oraz kodów BCH (Bose-Chaudhuri-Hocquenghem). Pożądanym efektem jest implementacja jednej z przedstawionych metod.
    
    \subsection{Struktura pracy}
    ? Zostawić na koniec pisania ?


\section{Wprowadzenie do uczenia maszynowego}\setcounter{figure}{0}
W tym rozdziale omówiono podstawowe definicje i pojęcia kryjące się za terminem uczenie maszynowe (ang. \textit{machine learning}) Przedstawiono opis zagadnienia, techniki uczenia modelu w sposób nadzorowany i nienadzorowany oraz najważniejsze informacje dotyczące przygotowania danych do treningu i testowania algorytmu.



% Jak podaje strona Seohost "\textit{W kontekście biznesowym technologie sztucznej inteligencji opierają się przede wszystkim na uczeniu maszynowym, głębokim uczeniu się na potrzeby analizy danych, generowania prognoz, kategoryzacji obiektów, przetwarzania języka naturalnego, rekomendacji i inteligentnego wyszukiwania danych.}"


    \subsection{Definicja uczenia maszynowego}
    Uczenie maszynowe jest poddziedziną sztucznej inteligencji (ang. \textit{Artificial Intelligence}), którą rozumie się jako umiejętność podejmowania samodzielnie decyzji przez urządzenie lub program, który wchodzi w interakcję z otoczeniem. Techniki uczenia maszynowego służą do przetwarzania danych z jego zmiennego środowiska, czego wynikiem jest bieżące dostosowywanie się do nowych informacji, na podstawie wcześniejszego doświadczenia lub nauki.
    
    Termin ten definiuje zdolność oprogramowania do rozpoznawania trendów z dużej ilości zgromadzonych danych (np. \textit{Big Data}). Jak trafnie ujęli autorzy książki \cite{valentino2018uczenie} uczenie maszynowe jest narzędziem stosowanym w zadaniach wielkoskalowego przetwarzania danych i świetnie nadaje się do obsługi złożonych zbiorów danych — tam, gdzie występuje ogromna liczba zmiennych i własności. Jedną z mocnych stron wielu technik uczenia maszynowego, a w szczególności uczenia głębokiego jest to, że techniki te pozwalają osiągnąć najlepsze wyniki wtedy, gdy są stosowane w odniesieniu do dużych zestawów danych — wtedy poprawiają się możliwości analizy i zdolność prognozowania.
    
    W wielu rozwiązaniach, wymagających ciągłego modyfikowania programu lub korzystania z nadmiernej ilości reguł, algorytm ML upraszcza aplikację oraz jej szybkość w porównaniu z tradycyjnymi metodami programowania, opierającymi się na statycznych i ręcznie tworzonych regułach i logice. Komputer ma możliwość uczenia i doskonalenia się w miarę zdobywania doświadczenia bez konieczności dostrajania algorytmu przez programistę. Jak zacytowano Tom Mitchell'a w książce \cite{geron2020uczenie} program komputerowy uczy się na podstawie doświadczenia E w odniesieniu do jakiegoś zadania T i pewnej miary wydajności P, jeśli jego wydajność (mierzona przez P) wobec zadania T wzrasta wraz z nabywaniem doświadczenia E.
    
    Do czterech głównych obszarów technik uczenia maszynowego zalicza się uczenie nadzorowane, nienadzorowane, półnadzorowane, przez wzmacnianie, wsadowe oraz przyrostowe. W ramach niniejszej pracy pochylono się nad dwoma pierwszymi zagadnieniami. Techniki te swoje zastosowania znajdują w dziedzinach takich jak: medycyna, finanse, marketing, wykrywanie oszustw i bezpieczeństwo, telekomunikacja oraz wiele innych.

    
    \subsubsection{Uczenie nadzorowane}
    Uczenie nadzorowane (ang. \textit{supervised learning}) jest sposobem uczenia modelu, w którym zbiór danych treningowych, na których uczy się algorytm, posiada przypisane rozwiązanie problemu, tzw. etykiety albo klasy. Określane również jako uczenie z nauczycielem, znajduje zastosowanie przede wszystkim w dwóch głównych obszarach jakimi są regresja i klasyfikacja. Pierwszy odnosi się do predykcji ciągłych wartości liczbowych. Natomiast drugi, definiuje się jako przypisanie danych do odpowiedniej kategorii. Poniższy wykres przedstawia podział danych w zależności od klasy.
    
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.5\linewidth]{nadzorowane.png}
        \caption{Przykład uczenia nadzorowanego \cite{valentino2018uczenie} }
        \label{nadzorowane}
    \end{figure}

    \noindent Do najpopularniejszych algorytmów nadzorowanego uczenia maszynowego zaliczamy:
    \begin{itemize}
        \item drzewa decyzyjne i lasy losowe
        \item regresja liniowa
        \item regresja logistyczna
        \item metoda k-najbliższych sąsiadów
        \item maszyny wektorów nośnych
        \item sieci neuronowe
    \end{itemize}

    
    \subsubsection{Uczenie nienadzorowane}
    Uczenie nienadzorowane (ang. \textit{unsupervised learning}) to metoda trenowania algorytmu, w której dane wejściowe nie mają przypisanych klas ani etykiet. Przekazywane do modelu nieoznakowane dane pozostawiają mu zadanie samodzielnego znalezienia wzorców i zależności. Proces ten nazywa się również uczeniem bez nauczyciela. Na rys. \ref{nienadzorowane} zaprezentowano sposób klasteryzacji zbioru punktów, który tworzy trzy podzbiory.

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.5\linewidth]{nienadzorowane.png}
        \caption{Przykład uczenia nienadzorowanego \cite{valentino2018uczenie}}
        \label{nienadzorowane}
    \end{figure}

    \noindent Najczęściej stosowanymi algorytmami nienadzorowanego uczenia maszynowego są:
    \begin{itemize}
        \item analiza skupień (ang. \textit{clustering})
        \item wizualizacja i redukcja nadmiarowości
        \item wykrywanie anomalii i nowości
        \item uczenie z użyciem reguł asocjacyjnych
    \end{itemize}


    \subsection{Przygotowanie danych}
    Niezwykle istotnym aspektem w dziedzinie uczenia maszynowego są dane. Algorytm ML uczy się na podstawie dostarczanych danych. Program może uczyć się skutecznie tylko wtedy, gdy te dane są czyste i kompletne. Nawet najbardziej zaawansowany algorytm może dostarczać niedokładne i wprowadzające w błąd rezultaty, jeśli informacje na wejście nie zostaną odpowiednio przygotowane.

    Dane można pozyskać między innymi: z istniejących zbiorów danych, za pomocą techniki automatycznego pozyskiwania danych ze stron internetowych (ang. \textit{web scraping}), za pomocą zewnętrznego API, czy też poprzez generowanie własnych danych. Przygotowując swój własny zbiór danych (ang. \textit{dataset}), warto kierować się podstawowymi zasadami, które zapewnią jego jakość, spójność i przydatność w rozwiązaniu danego problemu. Najpierw, należy określić cel i sposób predykcji algorytmu. Problem, który chce się rozwiązać, zwykle mieści się w jednej z trzech kluczowych kategorii: klasyfikacja, regresja lub klasteryzacja. Przechodząc do czyszczenia danych należy ujednolicić ich format, usunąć duplikaty i błędne rekordy oraz uzupełnić brakujące wiersze w zbiorze.
    
    Gotowy zbiór danych powinien zawierać od kilku do kilkuset tysięcy, a nawet milionów rekordów, zależnie od złożoności zadania. Dane w zbiorze należy podzielić na treningowe, walidacyjne oraz testowe. Stosunek podziału tych podzbiorów wynosi odpowiednio 70\%, 15\% i 15\%. W ramach niniejszego projektu inżynierskiego posłużono się częściej stosowaną techniką podziału zbioru danych. Mowa o podziale nieuwzględniającym danych walidacyjnych. Stosunek danych treningowych do danych testowych zwykle wynosi odpowiednio 80\% i 20\%. W obu podejściach warto pamiętać, iż wraz ze wzrostem rozmiaru całego zbioru danych można przeznaczyć proporcjonalnie większą część na zbiór treningowy, pozostawiając odpowiednią ilość danych na walidację i testy. Na przykład, z 1 000 000 rekordów pozostawiając 5\% na dane walidacyjne, 5\% na dane testowe oraz resztę na dane treningowe, taki podział w zupełności wystarczy. Dane walidacyjne i treningowe będą posiadały optymalną ilość — po 50 000 próbek.

    Dwoma niezwykle istotnymi zagadnieniamim w procesie nauki algorytmu z danych są nadmierne dopasowanie (ang. \textit{overfitting}) oraz niedostateczne dopasowanie (ang. \textit{underfitting}). Pierwszy termin odnosi się do sytuacji, w której predykcje modelu zbyt mocno dopasowują się do danych treningowych, co skutkuje brakiem generalizacji, gdy na wejściu algorytmu pojawią się nowe dane. Oznacza to, że model "uczy się na pamięć", zamiast rzeczywiście rozumieć zależności w danych i wyciągać ogólne wnioski. Przyczynami tego zjawiska są: zaszumiony lub zbyt mały zbiór danych, zastosowanie algorytmu o zbyt dużej złożoności, brak regularyzacji, czy też zbyt dużo epok treningowych. Niedostateczne dopasowanie modelu charakteryzuje się brakiem wykrywania istotnych zależności. Algorytm nie jest w stanie poprawnie przewidywać wyników na podstawie nowych danych na wejściu. Powodami tego zjawiska są: za mała ilość istotnych cech, za silna regularyzacja, zbyt prosty lub błędnie dobrany model. Ryzyko niedostatecznego dopasowania jest znacznie mniejsze, stąd większy nacisk kładzie się na uniknięcie nadmiernego dopasowania modelu. Poniżej zaprezentowano przykład obrazujący te zagadnienia.

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{overfitting_underfitting.png}
        \caption{Przykłady predykcji modelu uczenia maszynowego. Po lewej stronie nadmierne dopasowanie, po środku niedostateczne dopasowanie, po prawej stronie optymalne dopasowanie \cite{krohn2022uczenie} }
        \label{overfitting}
    \end{figure}
    


\section{Wprowadzenie do uczenia głębokiego}\setcounter{figure}{0}
W tym rozdziale skupiono się na zdefiniowaniu uczenia głębokiego (ang. \textit{deep learning}). W celu lepszego zrozumienia jego działania wyjaśniono czym jest sztuczny neuron oraz sztuczna sieć neuronowa. Ponadto, opisano najważniejsze właściwości konwolucyjnych i rekurencyjnych sieci neuronowych.
    
    \subsection{Sztuczny neuron}
    W roku 1943 Walter Pitts oraz Warren McCulloch przedstawili publikacją, w której ujęli matematyczny model biologicznego neuronu. Praca ta stanowiła fundament dla zrozumienia obliczeniowych właściwości neuronów i rozwoju sztucznych sieci neuronowych.
    
    Na wstępie, warto zdefiniować sztuczny neuron. Jest to matematyczny model, mający na celu odzwierciedlenie pracy biologicznego neuronu. Na wejścia sztucznego neuronu podawane są wyjścia jednostek połączonych do danego neuronu. Dla każdej z wartości wejściowych przypisana jest konkretna waga, oznaczająca jak istotna jest dana informacja.

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.75\linewidth]{sztuczny_neuron.png}
        \caption{Matematyczny model sztucznego neuronu}
        \label{sztuczny-neuron}
    \end{figure}
    
    Następuje sumowanie iloczynów odpowiednich wartości wejściowych $ x_{1,2,3, \dots,n} $ i ich wag $ w_{1,2,3, \dots,n} $. Następnie, do tej sumy dodawana jest wartość odchylenia $ b $ (ang. \textit{bias}), której celem jest umożliwienie modelowi lepszego przewidywania wyników w odpowiedzi na dane wejściowe poprzez przesunięcie funkcji aktywacji $ y $. Takim sposobem, znając wynik, można na jego podstawie obliczyć wartość tejże funkcji w następujący sposób.

    \begin{equation}
    \begin{aligned}
        z(x) &= \sum_{i=1}^{n} x_i w_i + b \\[10pt]
        y &= f(z)
    \end{aligned}
    \label{rownanie-neuronu}
    \end{equation}

    \noindent Funkcja aktywacji nie tylko określa wyjście neuronu, ale również pozwala wprowadzić nieliniowość do sieci neuronowej. Za jej przyczyną określa się czy neuron jest aktywny oraz w jakim stopniu. Do najpopularniejszych funkcji aktywacji należą: sigmoid, tangens hiperboliczny, ReLU, LeakyReLU oraz softmax.
    
    %charakterystykę neuronu. Popularne neurony: sigmoidalny, tangensowy ReLU. Wybór neuronu (a raczej funkcji aktywacji) zależy od celu ich stosowania. 
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.75\linewidth]{funkcje_aktywacji.png}
        \caption{Najczęściej stosowane funkcje aktywacji}
        \label{funkcje-aktywacji}
    \end{figure}
    
    \subsection{Sztuczna sieć neuronowa}
    Model sztucznej sieci neuronowej składa się z warstwy wejściowej, wyjściowej oraz tak zwanych warstw ukrytych. W teorii sieć może zawierać nieskończenie wiele sztucznych neuronów. Jak trafnie definiuje strona firmy IBM [? ? ?]: ”Sztuczne sieci neuronowe to uproszczony model procesu przetwarzania informacji przez ludzki umysł. Polega on na symulowaniu dużej liczby połączonych wzajemnie jednostek przetwarzania, które przypominają abstrakcyjne wersje neuronów".
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.7\linewidth]{siec_neuronowa.png}
        \caption{Przykład średniogłębokiej, w pełni połączonej sztucznej sieci neuronowa}
        \label{sztuczna-siec-neuronowa}
    \end{figure}
    
    Warstwa wejściowa stanowi reprezentację danych podanych do sieci. Każdy neuron odzwierciedla pojedynczą wartość z ciągu danych na wejście, więc nie są wykonywane obliczenia, lecz następuje przekazanie wartości wejściowych do kolejnych warstw. Liczba neuronów w warstwie wejściowej jest równa liczbie cech w danych wejściowych. W warstwach ukrytych dokonują się główne obliczenia w sztucznej sieci. To dzięki nim, model uczy się złożonych wzorców w danych podczas treningu. Ilość tych warstw oraz neuronów jest dowolna. Warstwa wyjściowa generuje wynik lub predykcję na podstawie przetworzonych danych. Liczba neuronów zależy od tego który z trzech problemów chcemy rozwiązać. Dla klasyfikacji wieloklasowej, liczba neuronów równa się liczbie klas. Na ich wyjściu generowane są prawdopodobieństwa przynależności do poszczególnych kategorii za pomocą funkcji aktywacji $ softmax $. Funkcja ta przekształca wyjścia neuronów na prawdopodobieństwa sumujące się do $ 1 $. Dla klasyfikacji binarnej zazwyczaj stosuje się jeden neuron z funkcją aktywacji \textit{sigmoid}. Regresję stosuje się w przypadku predykcji ciągłej wartości numerycznej stosując jeden neuron.

    Sztuczne sieci neuronowe można podzielić na płytkie, średniogłębokie oraz głębokie. Sieć płytka posiada jedną warstwę ukrytą lub wcale, średniogłęboka dwie warstwy ukryte, a głęboka trzy lub więcej. Dla każdego z tych wariantów istotnym terminem jest propagacja w przód (ang. \textit{forward propagation}). Jest to proces obliczenia wyjścia sieci, przekazując dane wejściowe przez jej warstwy, aż do warstwy wyjściowej. Dla każdego neuronu ze wszystkich warstw wykonywane jest obliczenie wartości funkcji aktywacji jak w równaniu \ref{rownanie-neuronu}.
    
    Najprostszym przykładem sieci neuronowej jest sieć typu wielowarstowy perceptron (ang. \textit{multilayer perceptron}). Jest to w pełni połączona sieć neuronowa — każdy neuron danej warstwy jest połączony ze wszystkimi neuronami znajdującymi się w kolejnej warstwie. Architektura ta jest niezwykle istotna przy modelowaniu nieliniowych zależności między wartościami wejściowymi, a ich predykcjami. Pomimo posiadania prostej struktury, stanowi fundament w projektowaniu bardziej zaawansowanych architektur takich jak konwolucyjne czy rekurencyjne sieci neuronowe.

    
    \subsection{Trening sztucznej sieci neuronowej}
    Treningiem sztucznej sieci neuronowej nazywamy iteracyjny proces dostrajania wag i odchyleń w celu doskonalenia predykcji wyników na wyjściu sieci — minimalizacja różnic pomiędzy przewidywaniami, a faktycznymi wartościami docelowymi. 

    Doskonalenie predykcji sieci polega na trzech fundamentalnych etapach. Na początek, następuje podaniu danych na wejście sieci (np. obraz, tekst lub wekor liczb) w celu rozpoczęcia propagacji w przód (ang. \textit{feedforward}). W drugim etapie, po otrzymaniu predykcji sieci następuje porównanie jej z wartością docelową, do czego stosuje się obliczenie funkcji straty (inaczej funkcji kosztu) — różnicy wyjścia sieci, a rzeczywistą etykietą. Jako trzeci etap, następuje propagacja wstecz (ang. \textit{backpropagation}). W tym kroku aktualizane są wagi neuronów za pomocą metody gradientu prostego \ref{gradient-prosty}, w celu poprawy obliczeń skutkującymi lepszą predykcją. Dąży się do minimalizacji funkcji straty, czego rezultatem jest zwiększenie skuteczności generowanych wyników dzięki zoptymalizowanym parametrom sieci. Błąd średniokwadratowy (ang. \textit{mean squared error} — MSE) stosuje się do obliczenia kosztu w problemach regresji. Natomiast, binarna entropia skrośna (ang. \textit{binary cross-entropy} — BCE) \ref{loss-functions} jest powszechnie wykorzystywana w problemie klasyfikacji binarnej.

    \begin{equation}
    \begin{aligned}
        {W_i}^{(j+1)} &= {W_i}^{(j)} - \eta \frac{ \partial L}{ \partial W_i}
    \end{aligned}
    \label{gradient-prosty}
    \end{equation}
    
    \begin{equation}
    \begin{aligned}
        MSE &= \frac{1}{n} \sum_{i=1}^{n} ( y_i - \hat{y}_i)^2\\[10pt]
        BCE &= - \frac{1}{n} \sum_{i=1}^{n} [  y_i \ln( \hat{y}_i ) + (1 - y_i) \ln( 1 - \hat{y}_i )  ] 
    \end{aligned}
    \label{loss-functions}
    \end{equation}

    \noindent We wzorze \ref{gradient-prosty} $ W_i $ oznacza macierz wag, $ \eta $ to współczynnik uczenia, a $ \frac{ \partial L}{ \partial W_i} $ oznacza gradient funkcji straty $ L $ względem macierzy wag $ W $. Natomiast we wzorze \ref{loss-functions} dla każdej próki o indeksie $ i $ wyliczany jest błąd pomiędzy rzeczywistą etykietą $ y_i $, a prognozą sieci $ \hat{y}_i $. Z kolei $ n $ jest liczbą próbek w zbiorze danych.

    Hiperparametrami nazywa się parametry, których wartości używane są do kontrolowania procesu uczenia oraz zwiększenia skuteczności i wydajności sztucznej sieci neuronowej. Na wstępie, zaleca się podzielić zbiór treningowy na mniejsze partie danych o rozmiarze (ang. \textit{batch size}) równym $ 2^n $. Celem takiego podejścia jest optymalizacja procesu uczenia modelu, dzięki mniejszym wymaganiom pamięciowym, przez co możemy trenować sieć na ogromnych zbiorach danych przy niewystarczających zasobach obliczeniowych RAM, GPU lub CPU. Następnie warto ustalić ilość iteracji treningu — epok treningowych (ang. \textit{epochs}). Epoka oznacza jedno kompletne przejście całego zestawu danych treningowych przez algorytm uczenia się. Każda epoka składa się z tylu iteracji ile jest mniejszych partii danych. Dla każdej z tych iteracji wykonywana jest propagacja w przód oraz propagacja wstecz. W treningu modelu, równie istotnym aspektem jest współczynnik uczenia (ang. \textit{learning rate}). Określa on, jak bardzo zmieniają się wagi sieci neuronowej w odniesieniu do minimalizacji funkcji kosztu — regulacja wielkości kroku w optymalizacji gradientowej. Kontynuując, jako optymalizator (ang. \textit{optimizer}) rozumie się algorytm używany do aktualizacji wag sieci w celu zmniejszenia kosztu, w odpowiedzi na obliczony gradient w propagacji wstecznej. Do popularnych optymalizatorów zaliczamy: SGD (ang. \textit{stochastic gradient decent}), Adam (ang. \textit{adaptive moment estimation}), RMSprop (ang. \textit{root mean square propagation}) oraz Adagrad (ang. \textit{adaptive gradient algorithm}). Jako ostatni hiperparametr omówiono dropout. Jest to technika regularyzacji stosowana w sieciach, która zapobiega przeuczeniu się modelu i pozwala na lepszą generalizację wyniku. Polega to na dezaktywacji losowej części neuronów z zadanym prawdopodobieństwem w trakcie treningu. 


    \subsection{Definicja uczenia głębokiego}
    Uczenie głębokie wywodzi się z obszaru sztucznych sieci neuronowych, będących poddziedziną uczenia maszynowego. Rozwiązanie inspirowane budową i funkcjonowaniem ludzkiego mózgu stosuje wielowarstwowe sieci neuronowe, zwane głębokimi sieciami neuronowymi (ang. \textit{deep neural networks}), składającymi się z trzech lub więcej ukrytych warstw neuronów. Calem nadawania głębokości sieci (stosowania wielu warstw) jest przystosowanie modelu do przetwarzania coraz bardziej złożonych reprezentacji danych oraz rozwiązywania skomplikowanych problemów. Poniżej zaprezentowano hierarchię omawianych zagadnień na wspólnym diagramie.

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.7\linewidth]{diagram_venna.png}
        \caption{Diagram Venna}
        \label{diagram-venna}
    \end{figure}
    
    Dzisiejszą popularność sztucznej inteligencji zawdzięczamy nie tylko dzięki ciężkiej pracy badaczy tworzących nowe rozwiązania, ale również dzięki rozwojowi sprzętu wykonującego obliczenia. Procesor graficzny (ang. \textit{graphics processing unit} — GPU) jest jednostką obliczeniową znajdującą się na kartach graficznych, stosowaną do przetwarzania grafiki komputerowej. Zaprojektowany do wykonywania wielu obliczeń równocześnie, korzystają z dużej liczby rdzeni obliczeniowych, nawet kilku tysięcy. Co więcej, chmury obliczeniowe takie jak Google Cloud, AWS oraz Microsoft Azure oferują dostęp do zaawansowanych zasobów obliczeniowych, bez konieczności inwestowania w drogi sprzęt komputerowy. Dużą popularność i efektywność uczenia głębokiego zawdzięczamy również dzięki dostępności dużych i różnorodnych zbiorów danych (ang. \textit{Big Data}). Ponadto, na bieżąco obserwuje się rozwój bibliotek jak TensorFlow, Keras czy PyTorch ułatwiających projektowanie wyspecjalizowanych modeli uczenia maszynowego. Do innowacyjnych architektur głębokich sieci neuronowych zalicza się: konwolucyjne i rekurencyjne sieci neuronowe, sieci GAN oraz transformery.

    
        \subsubsection{Splotowa sieć neuronowe CNN}
        Znajdująca swoje szerokie zastosowanie w wizji komputerowej i przetwarzaniu języka naturalnego, splotowa sieć neuronowa (ang. \textit{convolutional neural network}) jest wariantem głębokiej sieci neuronowej, składającym się z jednej lub więcej warstw konwolucyjnych. Ich zadaniem jest wykrywanie określonych wzorców w danych wejściowych. Każda z nich posiada tzw. filtry (ang. \textit{kernel}), będące macierzami dwu lub jednowymiarowymi, w zależności od wymiaru danych wejściowych. W przypadku przetwarzania obrazów często stosuje się filtry o rozmiarach 3x3 do nawet 7x7. Podczas przetwarzania wektorów kernele często mają rozmiary od 1x3 do 1x15. Filtry umożliwają efektywniejsze przetwarzanie obrazów wysokiej rozdzielczości (Full HD, 4K lub 8K), które dodatkowo posiadają więcej niż jeden kanał, jak na przykład kanały RGB.
        
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.5\linewidth]{filtry_rgb.png}
            \caption{Przykład filtrów o rozmiarach 3x3 stosowanych do przetwarzania obrazu posiadającego trzy kanały RGB \cite{krohn2022uczenie} }
            \label{filtry-rgb}
        \end{figure}
        
        Za pomocą filtrów stosuje się operację konwolucji na danych wejściowych czyli przesuwanie tzw. filtru, po np. dwuwymiarowym obrazie od lewej do prawej strony z góry na dół o zadany krok (ang. \textit{stride}). Z każdym kolejnym przesunięciem dokonywana jest operacja splotu — mnożenie elementów filtru (macierzy) z wartościami pikseli na wejściu, które są obecnie pokrywane. 
    
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.7\linewidth]{przesuwanie_filtru_cnn.png}
            \caption{Przesuwanie filtru po obrazie 2D z krokiem 1 \cite{valentino2018uczenie} }
            \label{konwolucja}
        \end{figure}
    
        Wynik każdej operacji przechodzi przez funkcję aktywacji czego rezultatem jest stworzenie warstwy aktywacji o rozmiarze:
        
        $$ height, width = \frac{D - F + 2P}{S} + 1 $$
        
        \noindent gdzie $ D $ to wysokość lub szerokość obrazu zależnie od obliczanego wymiaru, $ F $ to rozmiar filtra, $ P $ oznacza wypełnienie (ang. \textit{padding}) i $ S $ to krok o ile pikseli przesuwany jest filtr. Wypełnieniem nazywamy dodanie nadmiarowych pikseli wokół krawędzi obrazu wejściowego. Jeżeli nie zastosuje się wypełnienia, czyli $ P = 0 $ to rozmiar warstwy aktywacji jest mniejszy niż rozmiar obrazu na wejściu. W celu posiadania wymiaru warstwy aktywacji takiej jak obrazu wejściowego stosuje się wypełnienie zerami (ang. \textit{zero-padding}). W celu zmniejszenia rozmiaru tejże mapy cech, w tym optymalizacji obliczeń w następnym kroku stosuje się warstwę redukującą (ang. \textit{pooling layer}). Zazwyczaj posiada ona wymiar 2x2 dla obrazów lub 1x2 dla wektorów na wejście. Filtry w tej warstwie wykonują zadanie maksymalnej redukcji (ang. \textit{max pooling}). To znaczy, przechodząc przez mapę cech, dla każdego okna 2x2 wybierana jest największa wartość piksela. Po tym, powstaje nowa zredukowana mapa zawierająca najistotniejsze cechy. Na koniec następuje spłaszczenie (ang. \textit{flattening}) końcowej mapy cech w jednowymiarowy wektor i podanie go na wejście klasycznej w pełni połączonej sieci neuronowej w celu predykcji wyniku tradycyjną metodą. Często cały proces zawiera więcej niż pojedyncze warstwy konwolucyjne i redukujące.
    
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\linewidth]{cnn.png}
            \caption{Typowa architektura sieci konwolucyjnej CNN \cite{geron2020uczenie} }
            \label{cnn}
        \end{figure}
    
        
        \subsubsection{Losowa sieć neuronowa RNN}
        Jak podaje Erol Gelenbe, autor artykułu naukowego \cite{gelenbe1989random}, w losowej sieci neuronowej (ang. \textit{random neural network}) sygnały na wyjściu węzłów są dodatnie lub ujemne. Pozytywny sygnał na wejściu danego neuronu powoduje wzrost jego stanu wewnętrznego (potencjału) o 1. Negatywny sygnał zmniejsza potencjał o 1, tylko jeżeli ten potencjał jest większy od 0, lecz nie ma wpływu na neuron o potencjale równym 0. Kiedy wynikowy potencjał jest dodatni, neuron $ i $ aktywuje się (ang. \textit{fires}) w odstępach czasu o rozkładzie wykładniczym z wartością średnią $ \frac{1}{r (i)}$, gdzie $ r(i) $ jest częstością wyzwalania neuronu. Sygnały pozytywne reprezentują sygnały pobudzające, a negatywne odzwierciedlają sygnały tłumiące.

        Sygnały z zewnątrz podane do warstwy wejściowej lub wychodzące od innych neuronów w sieci przybywają do kolejnych neuronów za pomocą procesu Poissona o częstości odpowiednio $ \lambda ^+ (i) $ oraz $ \lambda ^- (i) $. Sygnał wychodzący z neuronu $ i $, kiedy ten się aktywuje zmierza do neuronu $ j $ z prawdopodobieństwem $ p^{+} (i,j) $ jako sygnał pozytywny lub jako sygnał negatywny z prawdopodobieństwem $ p^{-} (i,j) $. Sygnał ten może również opuścić sieć z prawdopodobieństwem $ d(i) $. Równanie \ref{prawdopodobienstwo} ukazuje prawdopodobieństwo przejścia w łańcuchu Markowa reprezentujące przebieg sygnału z neuronu $ i $ do neuronu $ j $. Również w drugiej linii równania pokazano, że prawdopodobieństwo, iż neuron $ i $ wyśle sygnał do samego siebie jest zerowe. 

        \begin{equation}
        \begin{aligned}
            p(i, j) &= p^{+} (i,j) + p^{-} (i,j) \\[10pt]
            p(i ,i) &= 0 \text{, dla każdego } i
        \end{aligned}
        \label{prawdopodobienstwo}
        \end{equation}

        \noindent Co więcej, suma prawdopodobieństw, że sygnał z neuronu $ i $ przejdzie do wszystkich możliwych nauronów $ j $ oraz że sygnał nie trafi do żadnego z $ j $ neuronów i opuści sieć wynosi 1, jak pokazano we wzorze \ref{p-d-rnn}.

        \begin{equation}
        \begin{aligned}
            \sum_j p(i, j) + d(i) = 1
        \end{aligned}
        \label{p-d-rnn}
        \end{equation}

        \noindent Wyniki predykcji losowej sieci neuronowej można interpretować znając prawdopodobieństwo aktywacji każdego neuronu z warstwy wyjściowej za pomocą wzoru \ref{p-aktywacji-rnn}.

        \begin{equation}
        \begin{aligned}
            q_i &= \frac{ \lambda ^+ (i) }{ r (i) + \lambda ^- (i) }, \; q_i \in [0, 1]
        \end{aligned}
        \label{p-aktywacji-rnn}
        \end{equation}
        
        \noindent Na przykład, przy ustaleniu progu na 0.5 jeżeli $ q_i \geq 0.5 $ to na wyjściu neuronu $ y_i $ otrzyma się binarne "1", czyli neuron został aktywowany. Jeżeli $ q_i < 0.5 $ to neuron jest nieaktywny i na wyjściu otrzyma się binarne "0".

        % Do warstwy wejściowej sieci podawane są sygnały pozytywne $ $ i negatywne $ $ określające na przykład cyfry binarne. Na wyjściu neurony aktywowane są w zależności od zadanego progu. Dzięki temu powyżej danego progu można otrzymać binarne "1", a poniżej binarne "0".



\section{Rozpoznanie korekcyjnych kodów blokowych}
W tym rozdziale wyjaśniono schemat modelu informacyjnego oraz sens kodowania kanałowego. Ponadto, pochylono się nad zdefiniowaniem korekcyjnych kodów blokowych i scharakteryzowaniem wywodzących się z nich kodów BCH oraz kodów Reeda-Solomona.  

    \subsection{Model systemu informacyjnego}
    Modelem systemu informacyjnego można nazwać uproszczoną reprezentację struktury, zachowań i funkcji systemu informacyjnego. Pozwala to na zrozumieniu, analizie oraz projektowaniu tego rodzaju systemów.

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.9\linewidth]{system_komunikacyjny.png}
        \caption{ Tradycyjny model dyskretnego systemu informacyjnego }
        \label{system-informacyjny}
    \end{figure}
    
    Pierwszym elementem modelu dyskretnego systemu informacyjnego jest źródło informacji. Najczęściej informacja składa się z reprezentacji binarnej, cyfr dziesiętnych lub liter alfabetu. Przy założeniu wysyłania wiadomości w takt zegara ciąg informacji trafia do kodera źródłowego. W tym układzie dostarczone wiadomości dzielone są na ciągi danych elementarnych. Najczęstszą przeszkodą pojawiającą się w rzeczywistych systemach komunikacyjnych jest maksymalna liczba symboli elementarnych, które mogą być transmitowane przez kanał w określonym przedziale czasu. Drugim blokiem na powyższym schemacie jest koder kanałowy, którego celem stosowania jest zapewnienie niezawodności w transmisji sekwencji podanej na jego wejściu. Dodawane są do niej nadmiarowe symbole, pomocne w uniknięciu przekłamania oryginalnej sekwencji podczas transmisji w kanale. Dzięki tej operacji, zwiększone jest prawdopodobieństwo odtworzenia oryginalnego ciągu symboli elementarnych. Modulator natomiast, na podstawie symboli wynikowych z kodera źródłowego, tworzy sygnał podawany na wejście kanału transmisyjnego najczęściej analogowego. Kanał ten jest fizycznym medium (np. kable miedziane lub powietrze), które umożliwia przesył informacji w postaci sygnałów między nadawcą a odbiorcą. Żadne medium nie jest idealnym nośnikiem informacji, więc zawsze wprowadza się przekłamanie danych wywołane przez źródło szumu. Kanał może przybierać formę zarówno przestrzenną, jak i czasową. Pierwsze określenie odnosi się do przesyłu wiadomości pomiędzy nadajnikiem a odbiornikiem znajdującymi się w różnych miejscach. Natomiast, drugi termin definiuje kanał zapisujący dane na nośnikach pamięci. W stosownej chwili, zapisy są odczytywane, a następnie dostarczane odbiorcy. Zadaniem demodulatora jest przekształcenie zaszumionego sygnału na wyjściu kanału w symbole elementarne. Dekoder kanałowy próbuje zrekonstruować oryginalnie zakodowaną wiadomość, na podstawie odczytanego błędnego bloku symboli elementarnych. Za sprawą dekodera źródłowego, niezależnie od skutku tego procesu, dany blok przekształcany jest w formę, która będzie zrozumiała dla odbiorcy.
    
    
    \subsection{Kodowanie kanałowe}
    Istotą kodowania kanałowego jest detekcja lub korekcja błędów. Współczesne systemy transmisji cyfrowej, zwłaszcza za pośrednictwem kanałów radiowych, niejednokrotnie umożliwiają rozwiązanie obu tych problemów równocześnie.

        \subsubsection{Proces kodowania kanałowego}
        Proces kodowania kanałowego opiera się na dwóch kluczowych zasadach. Pierwszą z nich jest wprowadzenie nadmiaru informacyjnego osiąganego za pośrednictwem rozszerzenia ciągu elementów oryginalnej wiadomości o dodatkowe symbole. Technika dobierania symboli, działa na takiej zasadzie, aby umożliwić odróżnienie danej wiadomości od innych nadanych. Ponadto, zakłada się bardzo wysokie prawdopodobieństwo, że zakłócony rozszerzony ciąg symboli podany na wejście odbiornika będzie możliwy do powiązania go z odpowiednią nadaną wiadomością.
    
        W bezpamięciowym binarnym kanale symetrycznym, powstawanie niezależnych błędów odbywa się z prawdopodobieństwem równym $ p $. Szansa $ P $ zaistnienia $ d $ błędów w n-elementowej sekwencji symboli dla danej wiadomości przedstawiona jest poniższym wzorem:
    
        \begin{equation}
        \begin{aligned}
            P = p^d ( 1 - p )^{n - d}
        \end{aligned}
        \label{pstwo}
        \end{equation}
    
        \noindent Reguła maksimum wiarygodności (ang. \textit{maximum likelihood estimation} — MLE) dowodzi, iż po odebraniu danego bloku binarnego należy spośród dostępnych sekwencji symboli wybrać tę, która charakteryzuje się najmniejszą odległością Hamminga $ d_{min} $ względem odebranej. Odległość ta jest równa liczbie pozycji na jakich dwa ciągi binarne o tej samej długości różnią się od siebie. W celu określenia maksymalnej liczby błędów, które kod korekcyjny może wykryć lub poprawić poprawić stosuje się odpowiednio wzory \ref{liczba-bledow-detekcja-korekcja}.
    
        \begin{equation}
        \begin{aligned}
            d_{max \_ detect} &= d_{min} - 1 \\[10pt]
            t_{max \_ correct} &= \left \lfloor \frac{d_{min} - 1}{2} \right \rfloor
        \end{aligned}
        \label{liczba-bledow-detekcja-korekcja}
        \end{equation} 
    
        \noindent Natomiast waga Hamminga $ w $ to liczba elementów o wartości $ 1 $ w słowie binarnym jak we wzorze\ref{waga-hamminga}. Na przykład dla 4-bitowego słowa $ 1011 $ waga $ w = 1+0+1+1 = 3 $.
    
        \begin{equation}
        \begin{aligned}
            w(x) = \sum_{i=1}^{n} x_i
        \end{aligned}
        \label{waga-hamminga}
        \end{equation} 
    
        \subsubsection{Dekodowanie twardo- i miękkodecyzyjne}
        Dekodowanie twardo- i miękkodecyzyjne opiera się na interpretacji odbieranych danych np. słowa binarnego w celu zrekonstruowania wiadomości oryginalnej, która została zakłócona w kanale transmisyjnym.

        Dekodowanie twardodecyzyjne (ang. \textit{hard decision decoding}) bazuje na dwupoziomowym układzie decyzyjnym. Dekodowanie to jest procesem odtwarzania oryginalnego sygnału cyfrowego z sygnału zakłóconego, w którym każda otrzymana wartość jest jednoznacznie przypisywana do jednego z możliwych symboli. To znaczy, że to jaką decyzję o wartości symbolu podejmie dekoder zależy od poziomu otrzymanego sygnału. Na przykład, w kodach binarnych jeżeli bitowi "0" będzie odpowiadał sygnał $ 1.0 V $, a bitowi "1" będzie odpowiadał sygnał $ -1.0 V $ należy ustalić próg decyzji o wartości symbolu. W tym przypadku:
        
        \begin{equation}
        \begin{aligned}
            \frac{1.0 V + (-1.0) V}{2} = 0.0 V
        \end{aligned}
        \label{dekodowanie-twardo}
        \end{equation}

        \noindent Posiadając tę wiedzę, jeżeli otrzyma się sygnały  $  -0.8V, 1.4V, -0.1V  $, to sygnały $ < 0.0V$ interpretujemy jako $ -1.0V $, czyli symbol "1". W odwrotnym przypadku otrzyma się symbol "0". Tym sposobem, wyniki dekodowania twardodecyzyjnego na podstawie przykładowej listy sygnałów są następujące: $ 1, 0, 1 $. Z rekonstrukcji bit po bicie słowa kodowego powstaje propozycja odtworzonej wiadomości. Na podstawie minimalnej odległości Hamminga następuje decyzja, jaka wiadomość została pierwotnie nadana. Dekodowanie twardodecyzyjne pozwala na poprawę $ \frac{d_{min} -1}{2} $ błędów. Technika ta jest prosta, lecz obliczeniowo nieefektywna.

        Dekodowanie miękkodecyzyjne (ang. \textit{soft decision decoding}) bazuje na zastosowaniu wielopoziomowego kwantyzatora. Ta zaawansowana technika odtwrzania sygnału cyfrowego bierze pod uwagę dodatkowe informacje o niepewności dotyczącej każdego odebranego symbolu. Istotą procesu tego dekodowania ciągów kodowych jest znalezienie maksymalnej korelacji pomiędzy odebranym zniekształconym sygnałem, a pierwotnie generowanymi sekwencjami kodowymi. Skutkuje to efektywniejszym zrekonstruowaniem pierwotnej wiadomości, której towarzyszą zakłócenia.
    
    
    \subsection{Definicja korekcyjnych kodów blokowych}
    Kody blokowe to klasyfikacja kodów, w których dane dzielone są na bloki o stałej długości, a każdy z bloków kodowany jest niezależnie. Szczególnym praktycznym przypadkiem są liniowe kody blokowe. Omówiona definicja bazuje na ciągach kodowych, których elementy są binarne. W aspekcie dodawania, liniowe kody blokowe tworzą grupę algebraiczną. Również, ciąg składający się z samych zer zalicza się do tychże kodów.

    \begin{equation}
    \begin{aligned}
        \textbf{a} &= [a_1, a_2, \dots, a_n] \text{ oraz } \textbf{b} = [b_1, b_2, \dots, b_n] \\[10pt]
        \textbf{a} + \textbf{b} &= \textbf{c} = [c_1, c_2, \dots, c_n] \text{, gdzie } c_i = { a_i } \oplus { b_i }
    \end{aligned}
    \label{kody-blokowe-wektory}
    \end{equation} 

    \noindent Kody blokowe opierające się na ciele wielomianów określa się kodami wielomianowymi.

    \begin{equation}
    \begin{aligned}
        \textbf{a} &= [a_0, a_1, \dots, a_{n-1}] \\[10pt]
        a(x) &= a_0  +  a_1 x  +  \dots  +  a_{n-1} x^{n-1}
    \end{aligned}
    \label{wielomian}
    \end{equation}

    
    Korekcyjne kody blokowe (ang. \textit{forward error correction block codes}) to kody blokowe posiadające dodatkową cechę. Umożliwiają wykrywanie błędów, a w niektórych przypadkach ich korekcję. Opisuje się je przez liczbę bitów kodu $ n $, długość wiadomości $ k $ oraz mnimalną odległość Hamminga $ d_{min} $. Do popularnych kodów blokowych zalicza się kody: Hamminga, Golay'a, BCH oraz Reeda-Solomona.
    

        \subsubsection{Macierz kontroli parzystości}
        [MACIERZ KONTROLI PATRZYSTOŚCI]

        
        \subsubsection{Macierz generująca}
        Kod można scharakteryzować znając zbiór słów kodowych oraz także poprzez przedstawienie pełnej kolekcji wielomianów kodowych o stopniu nie większym niż $ (n - 1) $. Wielomiany reprezentujące ciągi wielomianowego kodu odznaczają się tym, że ich wspólnym składnikiem jest wielomian generujący dany kod $ g(x) $. Umożliwia on wygenerowanie wszystkich słów kodowych z danej grupy kodowej.

        [MACIERZ GENERUJĄCA]


        \subsubsection{Ciało Galois}
        Nieodłącznym elementem tego działu jest pojęcie ciała skończonego (ang. \textit{Galois Field}) $ GF(q) $. Stanowi ono skończony zbiór $ q $ elementów. W ciele tym sformułowane są operacje dodawania i mnożenia. Suma i iloczyn dwóch elementów ciała zawierają się w tym ciele. Co więcej, w ciele tym mieści się element zerowy oraz jednostkowy, dla których zachodzą zależności:
        
        \begin{equation}
        \begin{aligned}
            \underset{a}{\bigwedge} \; a + 0 = a   \quad   \underset{a}{\bigwedge} \; a \cdot 1 = a
        \end{aligned}
        \label{element-zerowy-jednostkowy}
        \end{equation}
    
        \noindent Każdy element ciała ma element do niego przeciwstawny jak we wzore \ref{element-przeciwstawny}, a dla wszystkich niezerowych elementów ciała występuje element odwrotny jak to zaprezentowano na wzorze \ref{element-odwrotny}
    
        \begin{equation}
        \begin{aligned}
            \underset{a}{\bigwedge} \; \underset{ ( - a ) }{\bigvee}  \; a + ( - a ) = a
        \end{aligned}
        \label{element-przeciwstawny}
        \end{equation}
    
        \begin{equation}
        \begin{aligned}
            \underset{a \neq 0}{\bigwedge} \; \underset{ a^{-1} }{\bigvee}  \; a \cdot a^{-1} = a
        \end{aligned}
        \label{element-odwrotny}
        \end{equation}
    
        \noindent Również w ciele Galois występuje przemienność i łączność działań dodawania, a także rozłączność operacji mnożenia względem dodawania. Dla elementów ciała $ a $, $ b $ i $ c $ zachodzą zależności jak poniżej:
    
        \begin{equation}
        \begin{aligned}
            a + ( b + c ) = ( a + b ) + c \\[10pt]
            a + b = b + a \\[10pt]
            a ( b + c ) = a b + a c \\[10pt]
            a ( b c ) = ( a b ) c \\[10pt]
            a b = b a
        \end{aligned}
        \label{przemiennosc-lacznosc-rozlacznosc}
        \end{equation}
    
        \noindent Istnienie ciał Galois jest zależne od tego czy liczba ich elementów jest liczbą pierwszą lub potęgą liczby pierwszej. Dla pierwszej sytuacji mowa o ciele pierwotnym, a dla drugiej o ciele rozszerzonym.

        \subsubsection{Kody Hamminga}
    
        \subsubsection{Kody cykliczne}
        Kody cykliczne to wielomianowe kody blokowe, posiadające wyjątkową zaletę. Każde cykliczne przesunięcie (permutacja) słowa kodowego także jest słowem kodowym. Ciąg kodowy, którego znaki zostały przesunięte w lewo lub prawo, również jest prawidłowym ciągiem kodowym. Oznacza to, że jeżeli $ ( a_0, a_1, \dots, a_{n-1} ) $ jest słowem kodowym, to jest nim też $ ( a_1, a_2, \dots, a_{n-1}, a_0 ) $.

        
        \subsubsection{Kody BCH}
        Kody Bose–Chaudhuri–Hocquenghem (BCH) należą do rodziny kodów cyklicznych. Za pomocą kodów BCH możliwa jest korekcja więcej niż jednego błędu. Kod BCH mogący poprawić $ t $ błędów z elementami sekwencji kodowej będącej częścią ciała $ GF(q) $, posiada rozmiar słów kodowych równy $ n = q^m - 1 $. Ponadto, zawiera on pierwiastki wielomianu generującego $ g(x) = \alpha^{i_0}, \alpha^{i_0 + 1}, \dots, \alpha^{i_0 + 2t - 1} $, gdzie $ i_0 $ jest określoną początkową liczbą naturalną, a $ \alpha $ elementem generującym ciało $ GF(q^m) $. Należy pamiętać, że w praktyce kody BCH przedstawia się jako BCH($n$, $k$), gdzie $n$ oznacza długość zakodowanej wiadomości bitowej, a $k$ oznacza liczbę bitów oryginalnej wiadomości. 

        Kody BCH znajdują swoje zastosowanie w systemach telekomunikacyjnych, szczególnie w komunikacji bezprzewodowej takiej jak telefonia komórkowa oraz komunikacja satelitarna. Również, są szeroko wykorzystywane w kryptografii i systemach przechowywania danych takich jak płyty optyczne (DVD, CD, Blu-ray), dyski twarde, czy też pamięci flash.

    
        \subsubsection{Kody Reeda-Solomona}
        Kody Reeda-Solomona (RS) wywodzą się z kodów BCH. Należą do kodów, których elementy nie są reprezentacją binarną. Parametry dobrane są na podstawie kodów BCH i są równe $ i_0 = 1 $ oraz $ m = 1 $. Z tychże właściwości wynikają inne cechy kodów Reeda-Solomona. Sekwencje kodowe mają długości równe $ n = p - 1 $. Dla zdolności korekcyjnej $ t $ wielomian generujący prezentuje się następująco: $ g(x) = ( x - \alpha ) ( x - \alpha^2 ) \dots ( x - \alpha^{2t} ) $. Oznacza to, iż w celu poprawy $ t $ niebinarnych symboli konieczne jest wykorzystanie $ 2t $ symboli parzystości

        Kody RS, tak jak kody BCH, stosuje się w systemach komunikacji bezprzewodowej. Wykorzystuje się je również w przesyle danych za pomocą Ethernet, czy systemów światłowodowych. Aplikuje się je do odczytu nawet uszkodzonych kodów kreskowych i QR. Co więcej, kodów RS używa się także w systemach nawigacyjnych GPS oraz do przesyłu i przechowywania obrazów takich jak MRI, czy CT.
        


\section{Przegląd literatury}
W tym rozdziale zaprezentowano rozwiązania problemu będącego tematem niniejszej pracy dyplomowej na podstawie trzech różnych artykułów naukowych. Analiza literatury skoncentrowała się na znalezieniu sposobów poprawy jakości dekodowania kodów Hamminga i kodów BCH za pomocą technik uczenia maszynowego.


    % \subsection{Wstęp teoretyczny}
    % [2-3 zdania]

        % \subsubsection{Graf Tannera}
        % Grafem nazywa się strukturę matematyczną służącą do prezentacji oraz analizy relacji między obiektami. Określany jako $ G = (V, E) $ składa się z niepustego zbioru $ V = {v_1, v_2, \dots, v_n}$, którego komponenty nazywane są węzłami (ang. \textit{vertices}). Graf składa się również z par węzłów nazywanymi krawędziami (ang. \textit{edges}), które zawarte są w zbiorze $ E = { ( v_i, v_j ) } $.
    
        % \begin{figure}[H]
        %     \centering
        %     \includegraphics[width=0.7\linewidth]{graf.png}
        %     \caption{ Przykład grafu }
        %     \label{graf}
        % \end{figure}
    
        % \noindent Dla przykładowego grafu z Rys. \ref{graf} zbiór węzłów wynosi $ V = \{ v_1, v_2, v_3, v_4 \} $, a zbiór krawędzi wynosi $ E = \{ (v_1, v_2), (v_1, v_3), (v_2, v_1), (v_2, v_2), (v_2, v_3), (v_3, v_4) \} $. Stopniem węzła (ang. \textit{degree of a vertex}) $ d $ nazywa się liczbę krawędzi połączonych z danym węzłem. W powyższym przykładzie: $ d(v_1) = 3, d(v_2) = 5, d(v_3) = 3, d(v_1) = 1 $. Natomiast, dystansem $ d(v_i, v_j) $ określa się najmniejszą liczbę krawędzi łączących ze sobą węzły $ v_i $ oraz $ v_j $.
    
        % Ważnym wariantem grafu jest struktura, w której zbiór węzłów można podzielić na dwa rozłączne podzbiory $ V_1 $ i $ V_2 $ charakteryzujące się tym, że węzły należące do tej samej grupy nie są ze sobą połączone, za to połączone są z węzłami drugiej grupy. Taki graf określa się mianem grafu dwudzielnego (ang. \textit{bipartite graph}) i zaprezentowano na Rys, \ref{graf-dwudzielny}.

        % \begin{figure}[H]
        %     \centering
        %     \includegraphics[width=0.5\linewidth]{graf_dwudzielny.png}
        %     \caption{ Przykład grafu dwudzielnego }
        %     \label{graf-dwudzielny}
        % \end{figure}
        
        % Graf Tannera stanowi reprezentację macierzy kontroli parzystości, opisującej dany kod korekcyjny. Jest on grafem dwudzielnym, tzn. posiada dwie klasy węzłów, a każda łączy element z pierwszej klasy do drugiej. Grupa pierwsza $ V_1 $ zawiera tak zwane węzły zmienne (ang. \textit{variable nodes}), których jest $ n $, każdy odpowiadający pojedynczemu bitowi słowa kodowego, a zatem również każdą kolumną macierzy kontroli parzystości $ H $. Natomiast druga klasa $ V_2 $ zawiera węzły kontrolne (ang. \textit{check nodes}), których jest $ m $. Każdy z nich odpowiada wierszowi macierzy $ H $ sprawdzającemu parzystość zestawu bitów. Węzeł kontrolny $ c_j $ jest połączony z węzłem zmiennym $ v_j $, odzwierciedlającym bit słowa binarnego, jeżeli $ H_{i,j} = 1 $, tzn. jeżeli macierz $ H $ posiada $ 1 $ w wierszu $ j $ i kolumnie $ i $.

        % \begin{equation}
        % \begin{aligned}
        % H_{3,7} = 
        %     \begin{bmatrix}
        %     1 & 1 & 1 & 0 & 1 & 0 & 0 \\
        %     0 & 1 & 0 & 1 & 0 & 1 & 1 \\
        %     1 & 0 & 1 & 1 & 0 & 0 & 1
        %     \end{bmatrix}
        % \end{aligned}
        % \label{macierz-H}
        % \end{equation}

        % \noindent Przykład na podstawie macierzy $ H_{3,7} $ ze wzoru \ref{macierz-H} przedstawiono na Rys. \ref{graf-tannera-przyklad}, gdzie $ v_1, v_2, \dots, v_7 $ są węzłami zmiennymi, a $ c_1, c_2, c_3 $ są węzłami kontrolnymi, sprawdzającymi parzystość ciągu kodowego z odpowiednio $ 1 $, $ 2 $ i $ 3 $ wiersza macierzy, za pomocą operacji sumy modulo 2 elementów tego ciągu.

        % \begin{figure}[H]
        %     \centering
        %     \includegraphics[width=0.75\linewidth]{graf_tannera_przyklad.png}
        %     \caption{ Graf Tannera na podstawie macierzy $ H_{3,7} $ \ref{macierz-H} }
        %     \label{graf-tannera-przyklad}
        % \end{figure}
        
        
        % \subsubsection{Algorytm belief propagation}
        % Algorytm \textit{belief propagation} jest szeroko stosowany w uczeniu maszynowym oraz teorii informacji. Założeniem BP realizowanym w oparciu o graf Tannera jest przekazywanie wiadomości pomiędzy węzłami zmiennymi i węzłami konrolnymi w celu iteracyjnego wyznaczenia wartości bitów kodu, które minimalizują liczbę błędów. 


    % \subsection{Dekodowanie liniowych kodów blokowych z użyciem DNN}
    % W artykule \cite{nachmani2016dnndecoding} autorzy prezentują ulepszenie algorytmu \textit{belief propagation} BP poprzez [?przypisanie wag do krawędzi grafu Tannera. Krawędzie są następnie trenowane stosując tehchniki uczenia głębokiego?] Ogromną zaletą korzystania z algorytmu BP jest niezależność wydajności od transmitowanego słowa kodowego (ang. \textit{codeword}). Wyniki badań demonstrowane są z użyciem kodów BCH($ 63 $, $ 36 $), BCH($ 63 $, $ 45 $) i BCH($ 127 $, $ 106 $).


    % \subsection{Dekodowanie liniowych kodów blokowych z użyciem sieci RNN}
    % W artykule naukowym \cite{nachmani2017rnndecodinglinearblock} przedstawiono poprawioną wydajność w porównaniu z \textit{belief propagation} BP ulepszony o RNN od \cite{nachmani2016dnndecoding}

    
    \subsection{Technika dekodowania kodów Hamminga}
    W artykule \cite{abdelbaki1999random} autor proponuje model dekodera bazującego na losowej sieci neuronowej. Dekoder jest testowany za pomocą liniowych kodów Hamminga. Następnie wyniki są porównane z konwencjonalnym dekoderem twardodecyzyjnym oraz optymalnym dekoderem miękkodecyzyjnym.

    Dekoder RNN (RNND), zaprezentowany w artykule, zaprojektowany jest do dekodowania kodu Hamminga ($ 7 $, $ 4 $). Sieć zawiera dwie warstwy. Pierwszą jest warstwa wejściowa posiadająca 7 neuronów, które są ze sobą w pełni połączone. Natomiast drugą stanowi warstwa wyjściowa, która posiada 14 neuronów.

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.75\linewidth]{rnnd.png}
        \caption{ Struktura dekodera RNN \cite{abdelbaki1999random} }
        \label{rnnd}
    \end{figure}
    
    \noindent Węzły w sieci połączone są ze sobą jak na rysunku \ref{rnnd}. Neurony z warstwy wejściowej kolejno reprezentują elementy wiadomości zawierającej błędy. Każdy z neuronów wyjściowych reprezentuje 14 możliwych widomości kodowych Hamming ($7$, $4$), nie wliczając ciągu zerowego i jedynkowego. Podczas ogólnego treningu losowej sieci opartego o rozwiązanie \cite{gelenbe1993learning}, znajdowane są relacje między elementami na wejściu co odzwierciedla się w zapisaniu zaktualizowanych wag do dedykowanej macierzy. Warstwa wyjściowa pełni rolę warstwy klasyfikacyjnej, w której indeks neuronu wyjściowego wykazujący się najmniejszą wartością stanu neuronu wskazuje indeks zdekodowanej wiadomości bitowej ze zbioru czternastu pierwotnych ciągów. Warto wspomnieć, iż słów binarnych $ 0000000 $ i $ 1111111 $ nie zawarto w zbiorze treningowym i testowym z racji na osiągnięcie lepszych rezultatów dekodowania, niż gdy były zawarte. Aczkolwiek, jak podano w artykule, stosując identyczną strukturę sieci, ale posiadającą tylko 2 neurony klasyfikujące w warstwie wyjściowej trening przebiegł z zadowalającym skutkiem, przy dekodowaniu błędnie transmitowanych słów bitowych zerowych i jedynkowych.

    W procesie treningu sieci, wykorzystano każde możliwe wiadomości binarne kodu Hamminga ($7$,$4$), z wyjątkiem ciągu zerowego i jedynkowego. Każdy wektor reprezentujący dane słowo kodowe poddany został modulacji BPSK — bit "$0$" reprezentowany jako "$1$", a bit "$1$" reprezentowany jako "$-1$". Badania przeprowadzono z użyciem symulatora RNNMSIM v1.0 package.

    Po treningu sieci nastąpiła symulacja algorytmu. Utworzono trzy grupy testowe zaszumionych losowo wybranych słów kodowych testujących sieć. 7-bitowe słowa kodowe poddano modulacji BPSK, a następnie zostały zaszumione za pomocą białego addytywnego szumu gaussowskiego AWGN. Stosunek sygnału do szumu SNR wynosił najmniej $-1$ dB, a najwięcej $2$ dB. W tabeli \ref{3-groups} przedstawiono ilość błędnych pozycji (bitów) na słowo kodowe. Każdy ze zbiorów posiadał $ 10 $ tys. próbek. 

    \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{Nr grupy} & \textbf{Błędne pozycje na słowo kodowe}\\
    \hline
    1  & 1 \\
    2  & 2 \\
    3  & 3 \\
    \hline
    \end{tabular}
    \caption{Ilość błędnych pozycji na słowo kodowe dla każdej z trzech grup testowych}
    \label{3-groups}
    \end{table}

    \noindent Następnie dekodery HDD, RNND oraz SDD poddano testom. Wyniki dla każdego zbioru testowego, zaprezentowano w następujących tabelach:

    \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{SNR (dB)} & \textbf{HDD} & \textbf{RNND} & \textbf{SDD} \\
    \hline
    -1  & 0    & 0.071 & 0.057 \\
    0   & 0    & 0.043 & 0.036 \\
    1   & 0    & 0.027 & 0.022 \\
    2   & 0    & 0.006 & 0.004 \\
    \hline
    \end{tabular}
    \caption{Prawdopodobieństwo błędnie zdekodowanego ciągu dla pierwszej grupy}
    \end{table}
    
    \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{SNR (dB)} & \textbf{HDD} & \textbf{RNND} & \textbf{SDD} \\
    \hline
    -1  & 1    & 0.409 & 0.363 \\
    0   & 1    & 0.314 & 0.297 \\
    1   & 1    & 0.253 & 0.201 \\
    2   & 1    & 0.217 & 0.190 \\
    \hline
    \end{tabular}
    \caption{Prawdopodobieństwo błędnie zdekodowanego ciągu dla drugiej grupy}
    \end{table}
    
    \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{SNR (dB)} & \textbf{HDD} & \textbf{RNND} & \textbf{SDD} \\
    \hline
    -1  & 1    & 0.774 & 0.772 \\
    0   & 1    & 0.686 & 0.648 \\
    \hline
    \end{tabular}
    \caption{Prawdopodobieństwo błędnie zdekodowanego ciągu dla trzeciej grupy}
    \end{table}

    Rezultaty symulacji świadczą o tym, iż dla większej niż 1 ilości błędów na słowo binarne dekoder miękkodecyzyjny SDD sprawdza się najlepiej, dla każdego z poziomów zaszumienia SNR. Jednak, dekoder RNND nieznacznie od niego odstaje, podczas gdy dekoder HDD predykcjonuje poprawne wyniki z prawdopodobieństwem równym 0. Natomiast, dla ilości błędów na słowo kodowe równej 1, niezastąpiony jest klasyczny dekoder twardodecyzyjny, który dla każdego poziomu zaszumienia SNR ze stu procentową pewnością prawidłowo dekoduje błędne wiadomości. Wtem, na drugim miejscu plasuje się dekoder miękkodecyzyjny. Podsumowując, jeżeli nie jest się w stanie określić ile błędnych pozycji na słowo bitowe wprowadza zaszumiony kanał transmisyjny lub wiadomo, że liczba błędnych pozycji na słowo przekracza 1, najrozsądniejszym wyborem jest zastosowanie dekoder SDD.
    Największą wadą zaproponowanej losowej sieci neuronowej okazuje się być eksponencjalnie rosnąca liczba neuronów wyjściowych wraz ze zwiększającą się liczbą wiadomości kodowych, co jest niepraktyczne korzystając z kodów Hamminga dłuższych niż ($7$,$4$).

    
    \subsection{Technika odszumiania dla kodów BCH}
    W odróżnieniu od wcześniej opisanego artykułu, w pracy \cite{zhu2020novel} zaproponowano trzy różne warianty innowacyjnych odszumiaczy (ang. \textit{denoisers}) dla kodów BCH, w szczególności dla wersji (15,7) omówionej w artykule. Autorzy opisali sposób zaprojektowania następujących głębokich sieci neuronowych: wielowarstwowy perceptron, splotowa oraz rekurencyjna sieć neuronowa. Rozwiązania te stosowane są do wspomagania klasycznych algorytmów dekodowania kodów BCH. Wpierw błędne zakodowane wiadomości 15-bitowe są odszumiane przez sieć neuronową — zminimalizowanie liczby błędnych pozycji bitowych. Następnie, wynikowy ciąg trafia do tradycyjnego dekodera BCH, czego rezultatem jest 7-bitowe słowo, będące predykcją oryginalnej wiadomości. W niniejszej pracy dyplomowej pominięto omawianie rozwiązania bazującego na rekurencyjnej sieci neuronowej (ang. \textit{recurrent neural network} — RNN).

    Na rysunku \ref{denoiser-system-model} przedstawiono zaproponowany przez autorów model systemu dekodującego kody BCH oparty o odszumienie błędnej zakodowanej wiadomości za pomocą algorytmów głębokich sieci neuronowych.

   \begin{figure}[H]
        \centering
        \includegraphics[width=0.85\linewidth]{denoiser_system_model.png}
        \caption{ Model systemu inteligentnego odszumiacza dla kodów BCH \cite{zhu2020novel} }
        \label{denoiser-system-model}
    \end{figure}

    \noindent Na wejście do kodera BCH(15,7) podany jest 7-elementowy binarny wektor reprezentujący oryginalną wiadomość. Wynikiem jest 15-elementowy wektor binarny reprezentujący wiadomość zakodowaną. Wektor ten, jest następnie poddany modulacji BPSK. Następnie, do zamodulowanego wektora wprowadzany jest addytywny biały szum gaussowski AWGN. Tym sposobem, 15-elementowy wektor zaszumionego sygnału przekazany zostaje do odszumiacza na bazie sieci neuronowej. Następuje próba odtworzenia pierwotnego sygnału podanego na wejście sieci. Za pomocą demodulatora możliwe jest zmiana tego wyniku z powrotem na reprezentację binarną. Takim sposobem, odtworzony 15-elementowy binarny wektor jest podawany na wejście dekodera BCH(15,7). Rezultatem jest 7-elementowy wektor stanowiący predykcję oryginalnie podanej do systemu wiadomości.

    Odnośnie zaprojektowania algorytmów odszumiających opierających się o głębokie sieci neuronowe twórcy zaproponowali architektury przedstawione w tabeli \ref{denoiser-architektury-sieci}.

    \begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{|l|c|c|}
    \hline
    \textbf{Typ} & \textbf{MLP} & \textbf{CNN} \\ \hline
    \textbf{Warstwa wejściowa} & N          & N*1                            \\ \hline
    \textbf{Warstwa ukryta 1}  & Dense 256  & Conv1d 1*120*3 \& MaxPooling   \\ \hline
    \textbf{Warstwa ukryta 2}  & Dense 128  & Conv1d 120*84*3 \& MaxPooling  \\ \hline
    \textbf{Warstwa ukryta 3}  & Dense 64   & Conv1d 84*60*3 \& MaxPooling   \\ \hline
    \textbf{Warstwa wyjściowa} & Dense N    & Dense N                        \\ \hline
    \textbf{Łączna liczba parametrów} & 46223   & 46899                      \\ \hline
    \end{tabular}
    \caption{ Koncepcja dwóch architektur sieci będących odszumiaczami \cite{zhu2020novel} }
    \label{denoiser-architektury-sieci}
    \end{table}

    \noindent Z tabeli wyczytać można, że sieć MLP jak i sieć CNN posiadają warstwy wejściowe zawierające $ N $ neuronów. Reprezentują one elementy wektora na wyjściu kanału wprowadzającego szum. Dla kodu BCH(15,7) N wynosi $ 15 $. Dalej są 3 warstwy ukryte. Dla MLP są to warstwy w pełni połączonych neuronów z funkcją aktywacji ReLU, o liczbie kolejno: 256, 128 oraz 64 węzłów. Dla CNN natomiast, są to jednowymiarowe warstwy konwolucyjne. Liczby map cech wynoszą odpowiednio 120, 84, 60. Rozmiar filtru (ang. \textit{kernel size}) wynosi 3.  Po każdej z warstw konwolucyjnych dane przechodzą przez operację maxpoolingu o rozmiarze 2. Na wyjściu sieci jest $ N $ neuronów, identycznie jak na wejściu. Dla obu algorytmów, założono podobną liczbę wszystkich parametrów, aby uniknąć różnic w ich wydajności.

    W tym artykule, podczas badań posłużono się kodem BCH(15,7) o zdolności korekcji dwóch bitów. Jako dekoder BCH, użyto algorytmu Petersona z artykułu \cite{PetersonAlgorithm}. W zbiorze danych treningowych, którego wymiaru autorzy nie podali stosunek energii na bit do gęstości mocy szumu w sygnale $ E_b/N_0 $. Podczas wprowadzania szumu AWGN stosunek ten wynosił 0 dB. Dla zaszumionych danych testowych $ E_b/N_0 $ sięgało od 0 dB do 7 dB z krokiem co 1 dB — łącznie 8 poziomów zaszumienia. Rozmiar zbioru danych testowych wyniósł łącznie $ 10^6 $ próbek. Hiperparametry zastosowane do treningu sieci, które zostały wymienione w artykule, przedstawiono w tabeli \ref{parametry-sieci-denoiser}.

    \begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{|l|c|}
    \hline
    \textbf{Batch size} & 8          \\ \hline
    \textbf{Learning rate}  & 0.0005  \\ \hline
    \textbf{Epochs}  & $2^{14}$   \\ \hline
    \textbf{Optimizer}  & Adam  \\ \hline
    \end{tabular}
    \caption{ Hiperparametry sieci neuronowej \cite{zhu2020novel} }
    \label{parametry-sieci-denoiser}
    \end{table}

    Autorzy przeprowadzili badania za pomocą otwartoźródłowej platformy (ang. \textit{framework}) PyTorch stosowanej w dziedzinie uczenia głębokiego. Na wykresie \ref{denoiser-ber-performance} zaprezentowali swoje wyniki dla dekodera bez inteligentnego odszumiacza oraz dla trzech dekoderów z opracowanymi w artykule odszumiaczami. Rezultaty przedstawiono w funkcji bitowej stopy błędu (ang. \textit{bit error rate} — BER) od $ E_b/N_0 $. BER określa miarę jakości transmisji sygnału. Przedstawia proporcję błędnie przesłanych bitów w stosunku do całkowitej liczby przesłanych bitów.

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.70\linewidth]{denoiser_ber_performance.png}
        \caption{ Wydajność bitowej stopy błędów dla różnych poziomów zaszumienia \cite{zhu2020novel} }
        \label{denoiser-ber-performance}
    \end{figure}

    Z omawianych w tej sekcji rozwiązań, najlepiej poradził sobie algorytm dekodowania z odszumianiem za pomocą MLP. W tym przypadku SNR wzrosło aż o 5.5 dB porównując z tradycyjnym dekoderem. Niewiele mniej korzystne okazało się użycie konwolucyjnej sieci neuronowej. W tym rozwiązaniu, twórcom udało się zwiększyć SNR o 4.3 dB. Te jak i więcej rezultatów liczbowych przedstawia wykres SNR do $ E_b/N_0 $ \ref{denoiser-snr-performance}.

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.70\linewidth]{denoiser_snr_performance.png}
        \caption{ Wydajność stosunku sygnału do szumu dla różnych poziomów zaszumienia \cite{zhu2020novel} }
        \label{denoiser-snr-performance}
    \end{figure}
    
    Podsumowując, zastosowanie innowacyjnych odszumiaczy bazujących na głębokich sieciach neuronowych jest bezapelacyjnie korzystne. Gwarantują poprawę predykcji oryginalnych wiadomości binarnych przesyłanych za pomocą systemu telekomunikacyjnego, co udowodnili autorzy omawianego artykułu naukowego.


\section{Implementacja wybranego algorytmu}
Zdecydowano się na stworzeniu sieci MLP i CNN na podstawie artykułu \cite{zhu2020novel}, które zostały odpowiednio zmodyfikowana na rzecz projektu. Nie tylko stworzono narzędzia do odszumiania błędnych zakodowanych wiadomości, ale również do ich dekodowania.




% \section{Implementacja wybranego algorytmu uczenia głębokiego do poprawy jakości dekodowania wybranego korekcyjnego kodu blokowego 
% }


    \subsection{Cel badania}
    Cel
    
    \subsection{Narzędzia programistyczne}
    PyTorch, Anaconda, Python, Matlab, Jupyter Notebook
    
    \subsection{Zbiór danych}
    Sam wygenerowałem

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.3\linewidth]{bin_to_sign.png}
        \caption{ [...] }
        \label{bin-to-sign}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{add_awgn.png}
        \caption{ [...] }
        \label{add-awgn}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{train_dataset_created.png}
        \caption{ [...] }
        \label{train-dataset-created}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{test_dataset_created.png}
        \caption{ [...] }
        \label{test-dataset-created}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{train_dataset_bledy.png}
        \caption{ [...] }
        \label{train-dataset-bledy}
    \end{figure}
    
    
    \subsection{Przebieg badania}
    Dużo plików

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{mlp_class.png}
        \caption{ [...] }
        \label{mlp-class}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{mlp_denoiser_learning_chart.png}
        \caption{ [...] }
        \label{mlp-denoiser-learning-chart}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{mlp_decoder_learning_chart.png}
        \caption{ [...] }
        \label{mlp-decoder-learning-chart}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{mlp_denoiser_test_results.png}
        \caption{ [...] }
        \label{mlp-denoiser-test-results}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{mlp_decoder_test_results.png}
        \caption{ [...] }
        \label{mlp-decoder-test-results}
    \end{figure}
    


    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{cnn_class.png}
        \caption{ [...] }
        \label{cnn-class}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{cnn_denoiser_learning_chart.png}
        \caption{ [...] }
        \label{cnn-denoiser-learning-chart}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{cnn_decoder_learning_chart.png}
        \caption{ [...] }
        \label{cnn-decoder-learning-chart}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{cnn_denoiser_test_results.png}
        \caption{ [...] }
        \label{cnn-denoiser-test-results}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{cnn_decoder_test_results.png}
        \caption{ [...] }
        \label{cnn-decoder-test-results}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{output_updated.png}
        \caption{ [...] }
        \label{output-updated}
    \end{figure}


    
    \subsection{Analiza wyników}
    Zaskakująco dobrze

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{my_ber_results.png}
        \caption{ [...] }
        \label{my-ber-results}
    \end{figure}
    
    
    \subsection{Wnioski}
    Wnioski

\section{Podsumowanie}
Podsumowując, 
\newpage


% \bibliographystyle{plain}
\bibliography{literatura.bib}
\newpage


\listoffigures
\addcontentsline{toc}{section}{Wykaz rysunków} % Dodanie do spisu treści
\newpage


\listoftables
\addcontentsline{toc}{section}{Wykaz tabel}
\newpage

\end{document}